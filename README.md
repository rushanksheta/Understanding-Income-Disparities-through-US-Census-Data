# Understanding-Income-Disparities-through-US-Census-Data

### Project Overview
This project, conducted under the guidance of Prof. Stefan Weiergraeber, delves into the analysis of income disparities within the United States using Kaggle's Adult Census Income dataset from the 1994 Census Bureau database. The aim is to understand and predict income levels based on various socio-economic factors, such as occupation, education, and demographic characteristics.

### Abstract
The project utilizes machine learning algorithms, statistical techniques, and data visualization to explore the socioeconomic variables impacting income inequality in the U.S. The team employs methodologies such as Exploratory Data Analysis (EDA), data analysis, univariate and bivariate analysis, classification using algorithms like Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, and K Nearest Neighbors. Through data preprocessing, feature engineering, and model training, the project aims to predict income levels based on demographic attributes.

### 1. Introduction
The project seeks to advance understanding of income inequality in the U.S. by examining the socioeconomic factors impacting income levels. Using the Adult Census Income dataset, the study analyzes 32,562 cases with 15 attributes, including demographics, education, occupation, and financial parameters. Identifying the factors associated with income disparities can inform policy decisions and address systemic issues leading to unequal opportunities. Machine learning and data analysis offer powerful tools for overcoming these challenges.

### 2. Problem Statement
The project aims to explore income disparities in the U.S. by leveraging the Adult Census Income dataset. It seeks to understand and predict income levels based on socio-economic factors. The investigation involves data exploration, cleaning, and application of predictive modeling techniques to identify patterns, correlations, and anomalies in the dataset.

### 3. Methodology
The methodology involves data collection and exploration, data preprocessing, exploratory data analysis (EDA), modeling, model evaluation, and drawing conclusions. Univariate and bivariate data analyses provide insights into the distribution of variables and their relationships with income. Statistical analysis explores associations between variables. The project utilizes machine learning models, including Logistic Regression, Naive Bayes, K Nearest Neighbors, Decision Tree, Random Forest, and XGBoost.

### 4. Data Collection and Exploration
The training data contains attributes such as age, workclass, education, marital status, occupation, race, gender, capital gain/loss, hours per week, native country, and income. Data preprocessing involves handling missing values, feature engineering, and creating dummy variables for categorical attributes. Stratified sampling is used to split the processed data into training and testing sets.

### 5. Univariate Data Analysis
Visualizations are used to analyze the distribution of age, education number, and capital values. Insights are gained into the distribution of income across different segments, including age groups, workclasses, education levels, marital statuses, racial categories, gender, hours worked per week, and native countries.

### 6. Bivariate and Multivariate Data Analysis
Bivariate analysis includes bar charts illustrating patterns in hours worked by gender and boxplots showing the distribution of hours worked per week across different workclasses. Multivariate analysis explores the relationships between income and various factors, such as age, workclass, education, marital status, race, gender, hours worked per week, and native country. Statistical analysis involves formulating null hypotheses and examining p-values to determine associations between variables, such as income and sex, and income and race.

### 7. Modeling
The project employs various machine learning models, including Logistic Regression, Naive Bayes, K Nearest Neighbors, Decision Tree, Random Forest, and XGBoost. Each model is evaluated based on F1 Score, training accuracy, and testing accuracy.

### 8. Model Evaluation
A comprehensive table summarizes the F1 Score, training accuracy, and testing accuracy for each model. Decision Tree, Random Forest, and XGBoost emerge as strong contenders, with XGBoost exhibiting the best performance.

### 9. Conclusion and Future Scope
The investigation into income disparities provides valuable insights into influential factors impacting income levels. Logistic Regression, Decision Tree, Random Forest, and XGBoost demonstrate robust predictive capabilities. Future research could focus on addressing class imbalances, advanced feature engineering, ensemble models, and exploring more recent datasets to understand evolving income disparities over time.

